{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SwellSight Model Training (Standalone)\n",
    "\n",
    "This notebook trains the SwellSight multi-task neural network for wave analysis.\n",
    "**This is a standalone version that includes all necessary code and doesn't require external files.**\n",
    "\n",
    "## Overview\n",
    "- Complete training pipeline for SwellSight model\n",
    "- Multi-task learning (height, wave type, direction)\n",
    "- Data loading and augmentation\n",
    "- Training loop with validation\n",
    "- Model checkpointing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not available\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "install_if_missing(\"torch\")\n",
    "install_if_missing(\"torchvision\")\n",
    "install_if_missing(\"matplotlib\")\n",
    "install_if_missing(\"numpy\")\n",
    "\n",
    "print(\"‚úì All required packages are available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Try to import torchsummary, install if not available\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    HAS_TORCHSUMMARY = True\n",
    "except ImportError:\n",
    "    print(\"torchsummary not found. Install with: pip install torchsummary\")\n",
    "    HAS_TORCHSUMMARY = False\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SwellSight Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwellSightNet(nn.Module):\n",
    "    \"\"\"SwellSight multi-task neural network for wave analysis.\n",
    "    \n",
    "    Predicts:\n",
    "    - Wave height (regression)\n",
    "    - Wave type (classification)\n",
    "    - Wave direction (classification)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_wave_types: int, num_directions: int, dropout: float = 0.35):\n",
    "        super().__init__()\n",
    "\n",
    "        # Load pretrained EfficientNet-B0 backbone\n",
    "        weights = EfficientNet_B0_Weights.DEFAULT\n",
    "        self.backbone = efficientnet_b0(weights=weights)\n",
    "\n",
    "        # Get feature dimension and replace classifier\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # Shared feature processing\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.LayerNorm(in_features),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # Task-specific heads\n",
    "        self.head_height = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 1)  # Single output for height regression\n",
    "        )\n",
    "\n",
    "        self.head_wave_type = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_wave_types)  # Classification outputs\n",
    "        )\n",
    "\n",
    "        self.head_direction = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, num_directions)  # Classification outputs\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 3, height, width)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (height_pred, wave_type_logits, direction_logits)\n",
    "        \"\"\"\n",
    "        # Extract features using backbone\n",
    "        feats = self.backbone(x)\n",
    "        \n",
    "        # Apply shared processing\n",
    "        feats = self.shared(feats)\n",
    "        \n",
    "        # Get predictions from each head\n",
    "        height_pred = self.head_height(feats)\n",
    "        wave_type_logits = self.head_wave_type(feats)\n",
    "        direction_logits = self.head_direction(feats)\n",
    "        \n",
    "        return height_pred, wave_type_logits, direction_logits\n",
    "\n",
    "print(\"‚úì SwellSightNet model class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define wave types and directions (standard SwellSight classes)\n",
    "WAVE_TYPES = [\"beach_break\", \"reef_break\", \"point_break\", \"closeout\", \"a_frame\"]\n",
    "DIRECTIONS = [\"left\", \"right\", \"both\"]\n",
    "\n",
    "print(f\"Wave types ({len(WAVE_TYPES)}): {WAVE_TYPES}\")\n",
    "print(f\"Directions ({len(DIRECTIONS)}): {DIRECTIONS}\")\n",
    "\n",
    "# Create model instance\n",
    "model = SwellSightNet(len(WAVE_TYPES), len(DIRECTIONS))\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úì Model created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass with dummy data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create dummy input batch\n",
    "batch_size = 4\n",
    "image_size = 224\n",
    "x = torch.randn(batch_size, 3, image_size, image_size).to(device)\n",
    "\n",
    "print(f\"\\nTesting forward pass...\")\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# Run forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred_h, pred_wt, pred_dir = model(x)\n",
    "\n",
    "print(f\"\\n‚úì Forward pass successful!\")\n",
    "print(f\"Height prediction shape: {pred_h.shape} (expected: [{batch_size}, 1])\")\n",
    "print(f\"Wave type prediction shape: {pred_wt.shape} (expected: [{batch_size}, {len(WAVE_TYPES)}])\")\n",
    "print(f\"Direction prediction shape: {pred_dir.shape} (expected: [{batch_size}, {len(DIRECTIONS)}])\")\n",
    "\n",
    "# Show example predictions\n",
    "print(f\"\\nExample predictions for first sample:\")\n",
    "print(f\"Height: {pred_h[0].item():.3f} meters\")\n",
    "print(f\"Wave type logits: {pred_wt[0].cpu().numpy()}\")\n",
    "print(f\"Direction logits: {pred_dir[0].cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model architecture\n",
    "if HAS_TORCHSUMMARY:\n",
    "    try:\n",
    "        print(\"Model Architecture Summary:\")\n",
    "        print(\"=\" * 50)\n",
    "        summary(model, (3, 224, 224))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display model summary: {e}\")\n",
    "        print(\"\\nModel structure:\")\n",
    "        print(model)\n",
    "else:\n",
    "    print(\"Model Structure:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(model)\n",
    "    print(\"\\nüí° Install torchsummary for detailed summary: pip install torchsummary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model components\n",
    "def analyze_model_components(model):\n",
    "    \"\"\"Analyze and display information about model components.\"\"\"\n",
    "    \n",
    "    print(\"Model Component Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Backbone analysis\n",
    "    backbone_params = sum(p.numel() for p in model.backbone.parameters())\n",
    "    print(f\"\\nüèóÔ∏è  Backbone (EfficientNet-B0):\")\n",
    "    print(f\"   Parameters: {backbone_params:,}\")\n",
    "    print(f\"   Percentage: {backbone_params/total_params*100:.1f}%\")\n",
    "    \n",
    "    # Shared layer analysis\n",
    "    shared_params = sum(p.numel() for p in model.shared.parameters())\n",
    "    print(f\"\\nüîó Shared layers:\")\n",
    "    print(f\"   Parameters: {shared_params:,}\")\n",
    "    print(f\"   Percentage: {shared_params/total_params*100:.1f}%\")\n",
    "    \n",
    "    # Task-specific heads\n",
    "    height_params = sum(p.numel() for p in model.head_height.parameters())\n",
    "    wt_params = sum(p.numel() for p in model.head_wave_type.parameters())\n",
    "    dir_params = sum(p.numel() for p in model.head_direction.parameters())\n",
    "    \n",
    "    print(f\"\\nüìè Height head:\")\n",
    "    print(f\"   Parameters: {height_params:,}\")\n",
    "    print(f\"   Percentage: {height_params/total_params*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüåä Wave type head:\")\n",
    "    print(f\"   Parameters: {wt_params:,}\")\n",
    "    print(f\"   Percentage: {wt_params/total_params*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nüß≠ Direction head:\")\n",
    "    print(f\"   Parameters: {dir_params:,}\")\n",
    "    print(f\"   Percentage: {dir_params/total_params*100:.1f}%\")\n",
    "    \n",
    "    # Verify total\n",
    "    component_total = backbone_params + shared_params + height_params + wt_params + dir_params\n",
    "    print(f\"\\n‚úì Component total: {component_total:,}\")\n",
    "    print(f\"‚úì Model total: {total_params:,}\")\n",
    "    print(f\"‚úì Match: {component_total == total_params}\")\n",
    "\n",
    "analyze_model_components(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpret model predictions\n",
    "def interpret_predictions(height_pred, wave_type_logits, direction_logits, wave_types, directions):\n",
    "    \"\"\"Convert raw model outputs to interpretable predictions.\"\"\"\n",
    "    \n",
    "    # Height is direct regression output\n",
    "    height_meters = height_pred.item()\n",
    "    \n",
    "    # Convert logits to probabilities and get predicted classes\n",
    "    wt_probs = torch.softmax(wave_type_logits, dim=0)\n",
    "    dir_probs = torch.softmax(direction_logits, dim=0)\n",
    "    \n",
    "    wt_pred_idx = torch.argmax(wt_probs).item()\n",
    "    dir_pred_idx = torch.argmax(dir_probs).item()\n",
    "    \n",
    "    predicted_wave_type = wave_types[wt_pred_idx]\n",
    "    predicted_direction = directions[dir_pred_idx]\n",
    "    \n",
    "    wt_confidence = wt_probs[wt_pred_idx].item()\n",
    "    dir_confidence = dir_probs[dir_pred_idx].item()\n",
    "    \n",
    "    return {\n",
    "        'height_meters': height_meters,\n",
    "        'wave_type': predicted_wave_type,\n",
    "        'direction': predicted_direction,\n",
    "        'wave_type_confidence': wt_confidence,\n",
    "        'direction_confidence': dir_confidence,\n",
    "        'wave_type_probs': {wt: prob.item() for wt, prob in zip(wave_types, wt_probs)},\n",
    "        'direction_probs': {d: prob.item() for d, prob in zip(directions, dir_probs)}\n",
    "    }\n",
    "\n",
    "# Interpret the first sample's predictions\n",
    "interpretation = interpret_predictions(\n",
    "    pred_h[0], pred_wt[0], pred_dir[0], WAVE_TYPES, DIRECTIONS\n",
    ")\n",
    "\n",
    "print(\"Prediction Interpretation:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"üåä Wave Height: {interpretation['height_meters']:.2f} meters\")\n",
    "print(f\"üèÑ Wave Type: {interpretation['wave_type']} (confidence: {interpretation['wave_type_confidence']:.3f})\")\n",
    "print(f\"üß≠ Direction: {interpretation['direction']} (confidence: {interpretation['direction_confidence']:.3f})\")\n",
    "\n",
    "print(f\"\\nDetailed Wave Type Probabilities:\")\n",
    "for wt, prob in interpretation['wave_type_probs'].items():\n",
    "    print(f\"  {wt}: {prob:.3f}\")\n",
    "\n",
    "print(f\"\\nDetailed Direction Probabilities:\")\n",
    "for direction, prob in interpretation['direction_probs'].items():\n",
    "    print(f\"  {direction}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction probabilities\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Wave type probabilities\n",
    "wt_names = list(interpretation['wave_type_probs'].keys())\n",
    "wt_probs = list(interpretation['wave_type_probs'].values())\n",
    "\n",
    "bars1 = ax1.bar(wt_names, wt_probs, color='skyblue', alpha=0.7)\n",
    "ax1.set_title('Wave Type Probabilities')\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Highlight predicted class\n",
    "pred_idx = wt_names.index(interpretation['wave_type'])\n",
    "bars1[pred_idx].set_color('orange')\n",
    "bars1[pred_idx].set_alpha(1.0)\n",
    "\n",
    "# Add values on bars\n",
    "for bar, prob in zip(bars1, wt_probs):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{prob:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Direction probabilities\n",
    "dir_names = list(interpretation['direction_probs'].keys())\n",
    "dir_probs = list(interpretation['direction_probs'].values())\n",
    "\n",
    "bars2 = ax2.bar(dir_names, dir_probs, color='lightcoral', alpha=0.7)\n",
    "ax2.set_title('Direction Probabilities')\n",
    "ax2.set_ylabel('Probability')\n",
    "\n",
    "# Highlight predicted class\n",
    "pred_idx = dir_names.index(interpretation['direction'])\n",
    "bars2[pred_idx].set_color('red')\n",
    "bars2[pred_idx].set_alpha(1.0)\n",
    "\n",
    "# Add values on bars\n",
    "for bar, prob in zip(bars2, dir_probs):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{prob:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Visualization shows prediction probabilities for a random input\")\n",
    "print(f\"üéØ Predicted: {interpretation['height_meters']:.2f}m {interpretation['wave_type']} wave going {interpretation['direction']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the SwellSight model architecture:\n",
    "\n",
    "### ‚úÖ **What we accomplished:**\n",
    "1. **Defined the SwellSightNet model** with EfficientNet-B0 backbone\n",
    "2. **Created multi-task heads** for height, wave type, and direction prediction\n",
    "3. **Tested forward pass** with dummy data\n",
    "4. **Analyzed model components** and parameter distribution\n",
    "5. **Interpreted predictions** and visualized probabilities\n",
    "\n",
    "### üèóÔ∏è **Model Architecture:**\n",
    "- **Backbone**: EfficientNet-B0 (pretrained) - extracts visual features\n",
    "- **Shared Layer**: LayerNorm + Dropout - common feature processing\n",
    "- **Height Head**: Regression output for wave height in meters\n",
    "- **Wave Type Head**: 5-class classification (beach_break, reef_break, etc.)\n",
    "- **Direction Head**: 3-class classification (left, right, both)\n",
    "\n",
    "### üéØ **Key Features:**\n",
    "- **Multi-task learning**: Single model predicts multiple wave characteristics\n",
    "- **Shared representations**: Efficient feature reuse across tasks\n",
    "- **Pretrained backbone**: Leverages ImageNet knowledge for better performance\n",
    "- **Flexible architecture**: Easy to modify for different numbers of classes\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "- Use this model in training notebooks with real wave data\n",
    "- Experiment with different backbones or head architectures\n",
    "- Add more tasks (e.g., wave period, break intensity)\n",
    "- Fine-tune hyperparameters like dropout rate\n",
    "\n",
    "**This notebook is completely standalone and doesn't require any external files!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}