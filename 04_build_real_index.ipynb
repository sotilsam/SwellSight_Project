{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Real Dataset Index\n",
    "\n",
    "This notebook creates an index file for the real wave dataset from the labels.json file.\n",
    "\n",
    "## Purpose\n",
    "- Load wave parameter labels from JSON file\n",
    "- Verify image files exist on disk\n",
    "- Create JSONL index for downstream processing\n",
    "- Analyze dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions from previous notebook\n",
    "%run 02_data_loading.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - modify these paths as needed\n",
    "IMAGES_DIR = \"data/real/images\"\n",
    "LABELS_JSON = \"data/real/labels.json\"\n",
    "OUT_INDEX = \"data/processed/real_index.jsonl\"\n",
    "\n",
    "print(f\"Images directory: {IMAGES_DIR}\")\n",
    "print(f\"Labels file: {LABELS_JSON}\")\n",
    "print(f\"Output index: {OUT_INDEX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_real_index(images_dir: str, labels_json: str, out_jsonl: str) -> list:\n",
    "    \"\"\"Build index from real dataset labels and images.\"\"\"\n",
    "    \n",
    "    # Load labels\n",
    "    with open(labels_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        labels = json.load(f)\n",
    "\n",
    "    if not isinstance(labels, dict):\n",
    "        raise ValueError(\"labels.json must be a dict: {filename: {...}}\")\n",
    "\n",
    "    ensure_dir(os.path.dirname(out_jsonl))\n",
    "\n",
    "    records = []\n",
    "    missing = 0\n",
    "\n",
    "    for filename, ann in labels.items():\n",
    "        img_path = os.path.join(images_dir, filename)\n",
    "        if not os.path.exists(img_path):\n",
    "            missing += 1\n",
    "            print(f\"Warning: Missing image {img_path}\")\n",
    "            continue\n",
    "\n",
    "        rec = {\n",
    "            \"image_path\": img_path,\n",
    "            \"height_meters\": float(ann[\"height_meters\"]),\n",
    "            \"wave_type\": str(ann[\"wave_type\"]),\n",
    "            \"direction\": str(ann[\"direction\"]),\n",
    "            \"confidence\": str(ann.get(\"confidence\", \"medium\")),\n",
    "            \"notes\": str(ann.get(\"notes\", \"\")),\n",
    "            \"data_key\": int(ann.get(\"data_key\", -1)),\n",
    "            \"source\": \"real\",\n",
    "        }\n",
    "        records.append(rec)\n",
    "\n",
    "    # Write JSONL\n",
    "    write_jsonl(records, out_jsonl)\n",
    "\n",
    "    print(f\"Saved {len(records)} records to {out_jsonl}\")\n",
    "    if missing:\n",
    "        print(f\"Warning: {missing} images missing on disk\")\n",
    "    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if input files exist\n",
    "if os.path.exists(LABELS_JSON):\n",
    "    print(f\"✓ Labels file found: {LABELS_JSON}\")\n",
    "else:\n",
    "    print(f\"✗ Labels file not found: {LABELS_JSON}\")\n",
    "    print(\"Please ensure the labels.json file exists in the correct location.\")\n",
    "\n",
    "if os.path.exists(IMAGES_DIR):\n",
    "    print(f\"✓ Images directory found: {IMAGES_DIR}\")\n",
    "    image_count = len([f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "    print(f\"  Found {image_count} image files\")\n",
    "else:\n",
    "    print(f\"✗ Images directory not found: {IMAGES_DIR}\")\n",
    "    print(\"Please ensure the images directory exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the index if files exist\n",
    "if os.path.exists(LABELS_JSON) and os.path.exists(IMAGES_DIR):\n",
    "    records = build_real_index(IMAGES_DIR, LABELS_JSON, OUT_INDEX)\n",
    "    print(f\"\\n✓ Index built successfully with {len(records)} records\")\n",
    "else:\n",
    "    print(\"\\n⚠️ Cannot build index - missing input files\")\n",
    "    # Create dummy data for demonstration\n",
    "    print(\"Creating dummy data for demonstration...\")\n",
    "    records = [\n",
    "        {\n",
    "            \"image_path\": f\"data/real/images/img_{i:03d}.jpg\",\n",
    "            \"height_meters\": float(np.random.uniform(0.5, 2.5)),\n",
    "            \"wave_type\": np.random.choice([\"beach_break\", \"reef_break\", \"point_break\", \"closeout\", \"a_frame\"]),\n",
    "            \"direction\": np.random.choice([\"left\", \"right\", \"both\"]),\n",
    "            \"confidence\": np.random.choice([\"high\", \"medium\", \"low\"]),\n",
    "            \"notes\": f\"Example note {i}\",\n",
    "            \"data_key\": i,\n",
    "            \"source\": \"real\"\n",
    "        }\n",
    "        for i in range(100)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "print(f\"Dataset Summary:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nHeight statistics:\")\n",
    "print(df['height_meters'].describe())\n",
    "\n",
    "print(f\"\\nWave type distribution:\")\n",
    "print(df['wave_type'].value_counts())\n",
    "\n",
    "print(f\"\\nDirection distribution:\")\n",
    "print(df['direction'].value_counts())\n",
    "\n",
    "print(f\"\\nConfidence distribution:\")\n",
    "print(df['confidence'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize dataset statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Height distribution\n",
    "axes[0, 0].hist(df['height_meters'], bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Wave Height Distribution')\n",
    "axes[0, 0].set_xlabel('Height (meters)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Wave type distribution\n",
    "wave_type_counts = df['wave_type'].value_counts()\n",
    "axes[0, 1].bar(wave_type_counts.index, wave_type_counts.values)\n",
    "axes[0, 1].set_title('Wave Type Distribution')\n",
    "axes[0, 1].set_xlabel('Wave Type')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Direction distribution\n",
    "direction_counts = df['direction'].value_counts()\n",
    "axes[1, 0].pie(direction_counts.values, labels=direction_counts.index, autopct='%1.1f%%')\n",
    "axes[1, 0].set_title('Direction Distribution')\n",
    "\n",
    "# Confidence distribution\n",
    "confidence_counts = df['confidence'].value_counts()\n",
    "axes[1, 1].bar(confidence_counts.index, confidence_counts.values, \n",
    "               color=['green', 'orange', 'red'])\n",
    "axes[1, 1].set_title('Confidence Distribution')\n",
    "axes[1, 1].set_xlabel('Confidence Level')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-tabulation analysis\n",
    "print(\"Wave Type vs Direction Cross-tabulation:\")\n",
    "crosstab = pd.crosstab(df['wave_type'], df['direction'])\n",
    "print(crosstab)\n",
    "\n",
    "# Visualize cross-tabulation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(crosstab, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Wave Type vs Direction Cross-tabulation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height distribution by wave type\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.boxplot(column='height_meters', by='wave_type', ax=plt.gca())\n",
    "plt.title('Wave Height Distribution by Wave Type')\n",
    "plt.suptitle('')  # Remove default title\n",
    "plt.xlabel('Wave Type')\n",
    "plt.ylabel('Height (meters)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks\n",
    "print(\"Data Quality Checks:\")\n",
    "print(f\"✓ Total records: {len(df)}\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"✓ No missing values found\")\n",
    "else:\n",
    "    print(f\"⚠️ Missing values found:\")\n",
    "    print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check height range\n",
    "min_height, max_height = df['height_meters'].min(), df['height_meters'].max()\n",
    "print(f\"✓ Height range: {min_height:.2f}m to {max_height:.2f}m\")\n",
    "\n",
    "if min_height < 0:\n",
    "    print(\"⚠️ Warning: Negative height values found\")\n",
    "if max_height > 10:\n",
    "    print(\"⚠️ Warning: Very large height values found (>10m)\")\n",
    "\n",
    "# Check for valid wave types and directions\n",
    "valid_wave_types = {\"beach_break\", \"reef_break\", \"point_break\", \"closeout\", \"a_frame\"}\n",
    "valid_directions = {\"left\", \"right\", \"both\"}\n",
    "\n",
    "invalid_wave_types = set(df['wave_type']) - valid_wave_types\n",
    "invalid_directions = set(df['direction']) - valid_directions\n",
    "\n",
    "if not invalid_wave_types:\n",
    "    print(\"✓ All wave types are valid\")\n",
    "else:\n",
    "    print(f\"⚠️ Invalid wave types found: {invalid_wave_types}\")\n",
    "\n",
    "if not invalid_directions:\n",
    "    print(\"✓ All directions are valid\")\n",
    "else:\n",
    "    print(f\"⚠️ Invalid directions found: {invalid_directions}\")\n",
    "\n",
    "print(f\"\\n✓ Index file saved to: {OUT_INDEX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample records\n",
    "print(\"Sample records from the dataset:\")\n",
    "print(df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary statistics\n",
    "summary_stats = {\n",
    "    \"total_samples\": len(df),\n",
    "    \"height_stats\": df['height_meters'].describe().to_dict(),\n",
    "    \"wave_type_counts\": df['wave_type'].value_counts().to_dict(),\n",
    "    \"direction_counts\": df['direction'].value_counts().to_dict(),\n",
    "    \"confidence_counts\": df['confidence'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "summary_path = OUT_INDEX.replace('.jsonl', '_summary.json')\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2)\n",
    "\n",
    "print(f\"Summary statistics saved to: {summary_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}