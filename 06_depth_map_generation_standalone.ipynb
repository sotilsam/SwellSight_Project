{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SwellSight Wave Image Generation (Standalone)\n",
    "\n",
    "This notebook generates realistic wave images using AI (ControlNet + Stable Diffusion).\n",
    "**This is a standalone version that includes all necessary code and doesn't require external files.**\n",
    "\n",
    "## Overview\n",
    "- Generate depth maps from wave parameters\n",
    "- Create photorealistic wave images using AI\n",
    "- Different wave types: beach_break, reef_break, point_break, closeout, a_frame\n",
    "- Customizable wave height, direction, and characteristics\n",
    "- Export high-quality images for training or analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not available\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "install_if_missing(\"torch\")\n",
    "install_if_missing(\"torchvision\")\n",
    "install_if_missing(\"matplotlib\")\n",
    "install_if_missing(\"numpy\")\n",
    "install_if_missing(\"pillow\")\n",
    "install_if_missing(\"opencv-python\")\n",
    "install_if_missing(\"diffusers\")\n",
    "install_if_missing(\"transformers\")\n",
    "install_if_missing(\"accelerate\")\n",
    "\n",
    "print(\"‚úì All required packages are available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "from typing import Dict, Any, Tuple\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave Parameter Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_wave_params(rng=None):\n",
    "    \"\"\"Sample random wave parameters for generation.\"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    height_m = float(rng.uniform(0.2, 2.5))\n",
    "    wave_type = rng.choice([\"beach_break\", \"reef_break\", \"point_break\", \"closeout\", \"a_frame\"]).item()\n",
    "    direction = rng.choice([\"left\", \"right\", \"both\"]).item()\n",
    "    wavelength = float(rng.uniform(10.0, 28.0))\n",
    "    angle_deg = float(rng.uniform(-20.0, 20.0))\n",
    "    phase = float(rng.uniform(0.0, 2.0 * np.pi))\n",
    "\n",
    "    return {\n",
    "        \"height_meters\": height_m,\n",
    "        \"wave_type\": wave_type,\n",
    "        \"direction\": direction,\n",
    "        \"wavelength\": wavelength,\n",
    "        \"angle_deg\": angle_deg,\n",
    "        \"phase\": phase,\n",
    "        \"occlusion_mode\": \"none\",\n",
    "    }\n",
    "\n",
    "# Test parameter generation\n",
    "test_params = sample_wave_params()\n",
    "print(\"Sample wave parameters:\")\n",
    "for key, value in test_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_param_depth_map(params: Dict[str, Any], size: Tuple[int, int] = (768, 768), seed: int = 0) -> np.ndarray:\n",
    "    \"\"\"Generate a realistic wave depth map from parameters.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    H, W = size\n",
    "\n",
    "    # Normalized coordinates: x in [-1, 1], y in [0, 1]\n",
    "    x = np.linspace(-1.0, 1.0, W, dtype=np.float32)[None, :].repeat(H, axis=0)\n",
    "    y = np.linspace(0.0, 1.0, H, dtype=np.float32)[:, None].repeat(W, axis=1)\n",
    "\n",
    "    height = float(params.get(\"height_meters\", 1.0))\n",
    "    wave_type = str(params.get(\"wave_type\", \"beach_break\"))\n",
    "    direction = str(params.get(\"direction\", \"both\"))\n",
    "\n",
    "    # Base depth increases with y (farther is larger depth)\n",
    "    gamma = 1.7\n",
    "    y_p = y ** gamma\n",
    "    base_depth = 0.6 + 3.5 * y_p\n",
    "\n",
    "    # Direction controls breaker slant and approach angle\n",
    "    if direction == \"left\":\n",
    "        theta = np.deg2rad(18.0)\n",
    "        slant = 0.14\n",
    "    elif direction == \"right\":\n",
    "        theta = np.deg2rad(-18.0)\n",
    "        slant = -0.14\n",
    "    else:\n",
    "        theta = np.deg2rad(0.0)\n",
    "        slant = 0.0\n",
    "\n",
    "    # Wave frequency increases toward horizon (foreshortening)\n",
    "    wavelength = float(params.get(\"wavelength\", 18.0))\n",
    "    k0 = (2.0 * np.pi) / max(wavelength, 1e-3)\n",
    "    k = k0 * (1.0 + 2.8 * y_p)\n",
    "\n",
    "    u = np.cos(theta) * x + np.sin(theta) * (y_p - 0.55)\n",
    "    phase0 = float(params.get(\"phase\", 0.0))\n",
    "    phase = k * (u * 6.0) + phase0\n",
    "\n",
    "    # Keep relief smaller than base depth\n",
    "    amp = 0.08 + 0.18 * np.clip(height / 2.5, 0.0, 1.0)\n",
    "    wave_relief = amp * np.sin(phase)\n",
    "\n",
    "    # Soft spatial noise to avoid perfect stripes\n",
    "    n = rng.normal(0.0, 1.0, size=(H, W)).astype(np.float32)\n",
    "    n = cv2.GaussianBlur(n, (0, 0), sigmaX=3.0, sigmaY=3.0)\n",
    "    n = (n - n.min()) / (n.max() - n.min() + 1e-8)\n",
    "    noise_relief = (n - 0.5) * (0.04 + 0.03 * float(rng.random()))\n",
    "\n",
    "    # Breaking line position and shape by wave_type\n",
    "    break_y = 0.22 + 0.04 * float(rng.uniform(-1.0, 1.0))\n",
    "\n",
    "    if wave_type == \"closeout\":\n",
    "        curvature = 0.0\n",
    "        irregular = 0.0\n",
    "        slant *= 0.2\n",
    "    elif wave_type == \"a_frame\":\n",
    "        curvature = 0.10\n",
    "        irregular = 0.01\n",
    "        slant *= 0.3\n",
    "    elif wave_type == \"point_break\":\n",
    "        curvature = 0.03\n",
    "        irregular = 0.01\n",
    "        slant *= 1.2\n",
    "    elif wave_type == \"reef_break\":\n",
    "        curvature = 0.02\n",
    "        irregular = 0.03\n",
    "        slant *= 0.9\n",
    "    else:\n",
    "        curvature = 0.02\n",
    "        irregular = 0.015\n",
    "        slant *= 0.7\n",
    "\n",
    "    # Breaker line equation\n",
    "    if wave_type == \"a_frame\":\n",
    "        line = break_y + slant * x + curvature * np.abs(x)\n",
    "    else:\n",
    "        line = break_y + slant * x + curvature * (x ** 2)\n",
    "\n",
    "    # Irregularity along x\n",
    "    if irregular > 0:\n",
    "        ix = rng.normal(0.0, 1.0, size=(1, W)).astype(np.float32)\n",
    "        ix = cv2.GaussianBlur(ix, (0, 0), sigmaX=10.0)\n",
    "        ix = (ix - ix.min()) / (ix.max() - ix.min() + 1e-8)\n",
    "        ix = (ix - 0.5) * irregular\n",
    "        line = line + ix.repeat(H, axis=0)\n",
    "\n",
    "    breaker_band = np.exp(-((y - line) ** 2) / (2.0 * (0.012 ** 2))).astype(np.float32)\n",
    "    runup_band = np.exp(-((y - 0.10) ** 2) / (2.0 * (0.020 ** 2))).astype(np.float32)\n",
    "\n",
    "    breaker_relief = 0.35 * breaker_band\n",
    "    runup_relief = 0.22 * runup_band\n",
    "\n",
    "    depth = base_depth - wave_relief - noise_relief - breaker_relief - runup_relief\n",
    "\n",
    "    # Gentle shoreline slope near camera\n",
    "    shore_slope = 0.25 * (1.0 - y) ** 2\n",
    "    depth = depth - shore_slope\n",
    "\n",
    "    return depth.astype(np.float32)\n",
    "\n",
    "print(\"‚úì Depth map generation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth Map Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_normalize_to_u8(depth: np.ndarray, invert: bool = False, eps: float = 1e-8) -> np.ndarray:\n",
    "    \"\"\"Convert a float depth map to uint8 using robust percentile clipping.\"\"\"\n",
    "    d = np.asarray(depth, dtype=np.float32)\n",
    "\n",
    "    # Replace non-finite values to avoid breaking normalization\n",
    "    finite_mask = np.isfinite(d)\n",
    "    if not np.any(finite_mask):\n",
    "        return np.zeros(d.shape, dtype=np.uint8)\n",
    "\n",
    "    v = d[finite_mask]\n",
    "    lo = np.percentile(v, 2.0)\n",
    "    hi = np.percentile(v, 98.0)\n",
    "    if (hi - lo) < eps:\n",
    "        hi = lo + 1.0\n",
    "\n",
    "    d = np.clip(d, lo, hi)\n",
    "    d = (d - lo) / (hi - lo + eps)\n",
    "\n",
    "    if invert:\n",
    "        d = 1.0 - d\n",
    "\n",
    "    d_u8 = (d * 255.0).astype(np.uint8)\n",
    "\n",
    "    # If there were NaNs originally, set them to 0\n",
    "    if not np.all(finite_mask):\n",
    "        d_u8[~finite_mask] = 0\n",
    "\n",
    "    return d_u8\n",
    "\n",
    "\n",
    "def to_control_image(depth_u8: np.ndarray, size: tuple = (1024, 1024)) -> Image.Image:\n",
    "    \"\"\"Convert a uint8 depth map into a 3-channel PIL image, resized for ControlNet.\"\"\"\n",
    "    d = np.asarray(depth_u8)\n",
    "    if d.dtype != np.uint8:\n",
    "        d = d.astype(np.uint8)\n",
    "\n",
    "    # Ensure HxW\n",
    "    if d.ndim == 3:\n",
    "        d = d[..., 0]\n",
    "\n",
    "    # Resize with good quality\n",
    "    d_resized = cv2.resize(d, size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # ControlNet expects RGB-like input, replicate grayscale into 3 channels\n",
    "    rgb = np.stack([d_resized, d_resized, d_resized], axis=-1)\n",
    "    return Image.fromarray(rgb, mode=\"RGB\")\n",
    "\n",
    "print(\"‚úì Depth processing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Depth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample depth maps for different wave types\n",
    "wave_types = [\"beach_break\", \"reef_break\", \"point_break\", \"closeout\", \"a_frame\"]\n",
    "directions = [\"left\", \"right\", \"both\"]\n",
    "\n",
    "print(\"üåä Generating sample depth maps...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sample_data = []\n",
    "\n",
    "for i in range(6):\n",
    "    # Create specific parameters for variety\n",
    "    wave_type = wave_types[i % len(wave_types)]\n",
    "    direction = directions[i % len(directions)]\n",
    "    height = np.random.uniform(0.8, 2.2)\n",
    "    \n",
    "    params = {\n",
    "        \"height_meters\": height,\n",
    "        \"wave_type\": wave_type,\n",
    "        \"direction\": direction,\n",
    "        \"wavelength\": np.random.uniform(12.0, 25.0),\n",
    "        \"angle_deg\": np.random.uniform(-15.0, 15.0),\n",
    "        \"phase\": np.random.uniform(0, 2*np.pi),\n",
    "        \"occlusion_mode\": \"none\"\n",
    "    }\n",
    "    \n",
    "    # Generate depth map\n",
    "    depth_float = generate_param_depth_map(params, size=(512, 512), seed=i*42)\n",
    "    depth_u8 = robust_normalize_to_u8(depth_float, invert=True)\n",
    "    \n",
    "    # Store for later use\n",
    "    sample_data.append((depth_u8, params))\n",
    "    \n",
    "    # Visualize\n",
    "    im = axes[i].imshow(depth_u8, cmap='ocean', aspect='equal')\n",
    "    title = f\"{wave_type.replace('_', ' ').title()}\\n{height:.1f}m, {direction}\"\n",
    "    axes[i].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    print(f\"‚úì Generated: {wave_type} - {height:.1f}m - {direction}\")\n",
    "\n",
    "plt.suptitle('SwellSight Generated Wave Depth Maps', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüéâ Generated {len(sample_data)} depth maps successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Image Generation Setup (Optional)\n",
    "\n",
    "**Note**: This section requires significant computational resources and may take time to run. The depth maps above are already useful for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we want to generate AI images (requires more resources)\n",
    "GENERATE_AI_IMAGES = True  # Set to False to skip AI generation\n",
    "\n",
    "if GENERATE_AI_IMAGES:\n",
    "    try:\n",
    "        from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel\n",
    "        from diffusers.utils import load_image\n",
    "        \n",
    "        print(\"‚úì Diffusers library available\")\n",
    "        print(\"‚ö†Ô∏è  AI image generation will require downloading models (~6GB)\")\n",
    "        print(\"‚ö†Ô∏è  This may take 10-15 minutes per image on CPU\")\n",
    "        \n",
    "        # Ask user confirmation\n",
    "        proceed = input(\"\\nProceed with AI image generation? (y/n): \").lower().strip()\n",
    "        GENERATE_AI_IMAGES = proceed == 'y'\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Diffusers not available. Skipping AI image generation.\")\n",
    "        print(\"   Install with: pip install diffusers\")\n",
    "        GENERATE_AI_IMAGES = False\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  AI image generation disabled. Using depth maps only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_AI_IMAGES:\n",
    "    print(\"ü§ñ Setting up AI image generation pipeline...\")\n",
    "    \n",
    "    # Load ControlNet model for depth\n",
    "    controlnet = ControlNetModel.from_pretrained(\n",
    "        \"diffusers/controlnet-depth-sdxl-1.0\",\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
    "    )\n",
    "    \n",
    "    # Load Stable Diffusion XL pipeline\n",
    "    pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "        controlnet=controlnet,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "    \n",
    "    if device == \"cuda\":\n",
    "        pipe = pipe.to(device)\n",
    "    else:\n",
    "        # Enable CPU offloading for better memory management\n",
    "        pipe.enable_model_cpu_offload()\n",
    "    \n",
    "    print(\"‚úì AI pipeline ready!\")\n",
    "    \n",
    "    # Prompt templates\n",
    "    PROMPT_TEMPLATE = (\n",
    "        \"Ultra realistic beach camera photo, ocean water surface, waves breaking near shore, \"\n",
    "        \"visible shoreline and run-up foam, visible horizon line, oblique angle from sand level, \"\n",
    "        \"wave height about {height:.1f} meters, breaking type {wave_type}, peeling direction {direction}, \"\n",
    "        \"sea spray, whitewater, foam patterns, natural daylight, sharp focus, high detail, photo\"\n",
    "    )\n",
    "    \n",
    "    NEG_PROMPT = (\n",
    "        \"sand, dunes, desert, ripple sand, seabed, underwater, top-down, aerial, drone, \"\n",
    "        \"cartoon, illustration, painting, CGI, low detail, blurry, flat water, \"\n",
    "        \"text, watermark, logo, people, surfers, boats, buildings, \"\n",
    "        \"bokeh, lens flare, circular blur, circle artifact, ring, discs, spots\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Skipping AI setup - using depth maps only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate AI Wave Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_AI_IMAGES and 'pipe' in locals():\n",
    "    print(\"üé® Generating AI wave images...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"generated_wave_images\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    generated_images = []\n",
    "    \n",
    "    # Generate images for first 3 samples (to save time)\n",
    "    for i, (depth_u8, params) in enumerate(sample_data[:3]):\n",
    "        print(f\"\\nüñºÔ∏è  Generating image {i+1}/3...\")\n",
    "        \n",
    "        # Prepare control image\n",
    "        control_image = to_control_image(depth_u8, size=(1024, 1024))\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = PROMPT_TEMPLATE.format(\n",
    "            height=params['height_meters'],\n",
    "            wave_type=params['wave_type'],\n",
    "            direction=params['direction']\n",
    "        )\n",
    "        \n",
    "        print(f\"   Prompt: {prompt[:100]}...\")\n",
    "        \n",
    "        # Generate image\n",
    "        with torch.no_grad():\n",
    "            result = pipe(\n",
    "                prompt=prompt,\n",
    "                negative_prompt=NEG_PROMPT,\n",
    "                image=control_image,\n",
    "                num_inference_steps=20,  # Reduced for speed\n",
    "                guidance_scale=6.0,\n",
    "                controlnet_conditioning_scale=0.75,\n",
    "                generator=torch.Generator(device=device).manual_seed(42 + i)\n",
    "            )\n",
    "        \n",
    "        generated_image = result.images[0]\n",
    "        \n",
    "        # Save image\n",
    "        filename = f\"ai_wave_{i+1}_{params['wave_type']}_{params['height_meters']:.1f}m.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        generated_image.save(filepath)\n",
    "        \n",
    "        generated_images.append((generated_image, params, filename))\n",
    "        print(f\"   ‚úì Saved: {filename}\")\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(len(generated_images), 2, figsize=(16, 6*len(generated_images)))\n",
    "    if len(generated_images) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, (ai_image, params, filename) in enumerate(generated_images):\n",
    "        # Show depth map\n",
    "        axes[i, 0].imshow(sample_data[i][0], cmap='ocean')\n",
    "        axes[i, 0].set_title(f'Depth Map {i+1}', fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Show AI generated image\n",
    "        axes[i, 1].imshow(ai_image)\n",
    "        title = f\"AI Generated Wave\\n{params['wave_type'].replace('_', ' ').title()} - {params['height_meters']:.1f}m\"\n",
    "        axes[i, 1].set_title(title, fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüéâ Generated {len(generated_images)} AI wave images!\")\n",
    "    print(f\"üìÅ Images saved in: {output_dir}/\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  AI image generation skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Depth Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all depth maps\n",
    "depth_dir = \"depth_maps\"\n",
    "os.makedirs(depth_dir, exist_ok=True)\n",
    "\n",
    "print(\"üíæ Saving depth maps...\")\n",
    "\n",
    "saved_data = []\n",
    "\n",
    "for i, (depth_u8, params) in enumerate(sample_data):\n",
    "    # Save depth map as image\n",
    "    depth_filename = f\"depth_{i+1}_{params['wave_type']}_{params['height_meters']:.1f}m.png\"\n",
    "    depth_path = os.path.join(depth_dir, depth_filename)\n",
    "    Image.fromarray(depth_u8, mode='L').save(depth_path)\n",
    "    \n",
    "    # Save parameters\n",
    "    record = {\n",
    "        \"depth_path\": depth_path,\n",
    "        \"height_meters\": params['height_meters'],\n",
    "        \"wave_type\": params['wave_type'],\n",
    "        \"direction\": params['direction'],\n",
    "        \"wavelength\": params['wavelength'],\n",
    "        \"angle_deg\": params['angle_deg'],\n",
    "        \"source\": \"notebook_generated\"\n",
    "    }\n",
    "    \n",
    "    saved_data.append(record)\n",
    "    print(f\"‚úì Saved: {depth_filename}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata_path = os.path.join(depth_dir, \"metadata.json\")\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(saved_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìã Metadata saved: {metadata_path}\")\n",
    "print(f\"üìÅ All depth maps saved in: {depth_dir}/\")\n",
    "print(f\"\\nüéâ Wave generation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully generated:\n",
    "\n",
    "### ‚úÖ Depth Maps\n",
    "- High-quality wave depth maps for different wave types\n",
    "- Realistic wave characteristics (height, direction, breaking patterns)\n",
    "- Saved as PNG images with metadata\n",
    "\n",
    "### ‚úÖ AI Images (Optional)\n",
    "- Photorealistic wave images generated from depth maps\n",
    "- Uses Stable Diffusion XL + ControlNet\n",
    "- Customizable wave parameters\n",
    "\n",
    "### üéØ Use Cases\n",
    "- **Training Data**: Use generated images to train SwellSight models\n",
    "- **Testing**: Validate model performance on synthetic data\n",
    "- **Augmentation**: Expand existing datasets with controlled variations\n",
    "- **Research**: Study wave characteristics and breaking patterns\n",
    "\n",
    "### üìÅ Output Files\n",
    "- `depth_maps/`: Depth map images and metadata\n",
    "- `generated_wave_images/`: AI-generated photorealistic waves (if enabled)\n",
    "\n",
    "**Next Steps**: Use these generated images with other SwellSight notebooks for training and analysis!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}